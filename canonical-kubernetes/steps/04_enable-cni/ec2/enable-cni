#!/bin/bash

set -eu

abort() {
    >&2 echo "$@"
    echo "Unable to enable AWS integration"
    setResult "Unable to enable AWS integration (see logs for details)"
    exit 0
}

data_dir="$(dirname "$BASH_SOURCE")"
if ! aws_account_id=$(aws sts get-caller-identity \
                      --profile "$JUJU_CREDENTIAL" \
                      --output text --query 'Account' 2>&1); then
    abort "Unable to determine account ID: $aws_account_id"
fi

load_iam_policy() {
    role="$1"  # master or worker
    echo "Creating IAM policy: juju-kubernetes-$role"
    if ! result=$(aws iam create-policy \
                  --profile "$JUJU_CREDENTIAL" \
                  --policy-name "juju-kubernetes-$role" \
                  --policy-document "file://$data_dir/policy-$role.json" \
                  --query 'Policy.PolicyId' \
                  --output text 2>&1); then
        if [[ "$result" == *"already exists"* ]]; then
            >&2 echo "IAM policy juju-kubernetes-$role already exists"
            return
        fi
        abort "$result"
    fi
    >&2 echo "IAM policy juju-kubernetes-$role created: $result"
}

load_iam_role() {
    role="$1"  # master or worker
    echo "Creating IAM role: juju-kubernetes-$role"
    if ! result=$(aws iam create-role \
                  --profile "$JUJU_CREDENTIAL" \
                  --role-name "juju-kubernetes-$role" \
                  --assume-role-policy-document "file://$data_dir/role.json" \
                  --query 'Role.RoleId' \
                  --output text 2>&1); then
        if [[ "$result" == *"already exists"* ]]; then
            >&2 echo "IAM role juju-kubernetes-$role already exists"
            return
        fi
        abort "$result"
    fi
    >&2 echo "IAM role juju-kubernetes-$role created: $result"
}

create_instance_profile() {
    role="$1"  # master or worker
    echo "Creating instance profile: juju-kubernetes-$role"
    if ! result=$(aws iam create-instance-profile \
                  --profile "$JUJU_CREDENTIAL" \
                  --instance-profile-name "juju-kubernetes-$role" \
                  --query 'InstanceProfile.InstanceProfileId' \
                  --output text 2>&1); then
        if [[ "$result" == *"already exists"* ]]; then
            >&2 echo "Instance profile juju-kubernetes-$role already exists"
            return
        fi
        abort "$result"
    fi
    >&2 echo "Instance profile juju-kubernetes-$role created: $result"
}

attach_policy_to_role() {
    role="$1"  # master or worker
    echo "Attaching IAM policy juju-kubernetes-$role to IAM role juju-kubernetes-$role"
    if ! result=$(aws iam attach-role-policy \
                  --profile "$JUJU_CREDENTIAL" \
                  --role-name "juju-kubernetes-$role" \
                  --policy-arn "arn:aws:iam::$aws_account_id:policy/juju-kubernetes-$role" 2>&1); then
        abort "$result"
    fi
    >&2 echo "IAM policy juju-kubernetes-$role attached to IAM role juju-kubernetes-$role"
}

add_role_to_profile() {
    role="$1"  # master or worker
    echo "Adding IAM role juju-kubernetes-$role to instance profile juju-kubernetes-$role"
    if ! result=$(aws iam add-role-to-instance-profile \
                  --profile "$JUJU_CREDENTIAL" \
                  --role-name "juju-kubernetes-${role}" \
                  --instance-profile-name "juju-kubernetes-$role" 2>&1); then
        if [[ "$result" == *"Cannot exceed quota"* ]]; then
            >&2 echo "IAM role juju-kubernetes-$role already on instance profile juju-kubernetes-$role"
            return
        fi
        abort "$result"
    fi
    >&2 echo "IAM role juju-kubernetes-$role added to instance profile juju-kubernetes-$role"
}

get_instance_ids() {
    role="$1"  # master or worker
    instances="$(juju status -m "$JUJU_CONTROLLER:$JUJU_MODEL" "kubernetes-$role*" --format=yaml | grep instance-id | awk '{print $2}')"
    if [[ -z "$instances" ]]; then
        abort "Unable to find kubernetes-$role instances"
    fi
    echo "$instances" | tr '\n' ' '
}

attach_profile_to_instances() {
    role="$1"  # master or worker
    instances="$(get_instance_ids "$role")"
    for instance in $instances; do
        instance_id="$(cut -d, -f1 <<< "$instance")"
        unit_name="$(cut -d, -f2 <<< "$instance")"
        echo "Attaching instance profile juju-kubernetes-$role to $unit_name"
        if ! result=$(aws ec2 associate-iam-instance-profile \
                      --profile "$JUJU_CREDENTIAL" \
                      --region "$JUJU_REGION" \
                      --iam-instance-profile Name="juju-kubernetes-$role" \
                      --instance-id "$instance_id" \
                      --query 'IamInstanceProfileAssociation.AssociationId' \
                      --output text 2>&1); then
            abort "$result"
        fi
        >&2 echo "Instance $instance_id ($unit_name) associated with profile juju-kubernetes-$role: $result"
    done
}

get_security_groups() {
    instances="$1"
    sg_type="$2"  # shared or unique
    if [[ "$sg_type" == "shared" ]]; then
        sg_flag="-v"
    else
        sg_flag=""
    fi
    # shellcheck disable=SC2086
    if ! group_ids="$(aws ec2 describe-instances \
                      --profile "$JUJU_CREDENTIAL" \
                      --region "$JUJU_REGION" \
                      --instance-ids $instances \
                      --query "Reservations[0].Instances[0].SecurityGroups[*].[GroupId,GroupName]" \
                      --output text | grep $sg_flag -- 'juju.*-.$' | awk '{print $1}' 2>&1)"; then
        abort "$group_ids"
    fi
    if [[ "$group_ids" == None ]]; then
        abort "Unable to locate $sg_type Security Groups for $instances"
    fi
    echo "$group_ids"
}

remove_shared_security_group_tag() {
    role="$1"  # master or worker
    instances="$(get_instance_ids "$role")"
    group_id="$(get_security_groups "$instances" shared)"
    echo "Removing KubernetesCluster tag from shared security group for kubernetes-$role"
    # shellcheck disable=SC2086
    if ! result=$(aws ec2 delete-tags \
                  --profile "$JUJU_CREDENTIAL" \
                  --region "$JUJU_REGION" \
                  --tags "Key=KubernetesCluster" \
                  --resources $group_id 2>&1); then
        abort "$result"
    fi
    >&2 echo "Removed KubernetesCluster tag from $group_id for kubernetes-$role"
}

tag_application() {
    role="$1"  # master or worker
    tag="$2"
    instances="$(get_instance_ids "$role")"
    group_ids="$(get_security_groups "$instances" unique)"
    echo "Tagging kubernetes-$role with KubernetesCluster=$tag"
    # shellcheck disable=SC2086
    if ! result=$(aws ec2 create-tags \
                  --profile "$JUJU_CREDENTIAL" \
                  --region "$JUJU_REGION" \
                  --tags "Key=KubernetesCluster,Value=$tag" \
                  --resources $instances $group_ids 2>&1); then
        abort "$result"
    fi
    if [[ "$role" == "master" ]]; then
        # shellcheck disable=SC2086
        if ! result=$(aws ec2 create-tags \
                      --profile "$JUJU_CREDENTIAL" \
                      --region "$JUJU_REGION" \
                      --tags "Key=k8s.io/role/master,Value=true" \
                      --resources $instances 2>&1); then
            abort "$result"
        fi
    fi
    >&2 echo "Created tag KubernetesCluster=$tag on $instances $group_id"
}

tag_subnets() {
    role="$1"  # master or worker
    tag="$2"
    instances="$(get_instance_ids "$role")"
    # shellcheck disable=SC2086
    if ! subnet_ids="$(aws ec2 describe-instances \
                       --profile "$JUJU_CREDENTIAL" \
                       --region "$JUJU_REGION" \
                       --instance-ids $instances \
                       --query "Reservations[*].Instances[*].SubnetId" \
                       --output text | tr '\n' ' ' 2>&1)"; then
        abort "$subnet_ids"
    fi
    if [[ "$subnet_ids" == None ]]; then
        abort "Unable to locate subnets for kubernetes-$role"
    fi
    echo "Tagging kubernetes-$role subnets with KubernetesCluster=$tag"
    # shellcheck disable=SC2086
    if ! result=$(aws ec2 create-tags \
                  --profile "$JUJU_CREDENTIAL" \
                  --region "$JUJU_REGION" \
                  --tags "Key=KubernetesCluster,Value=$tag" \
                  --resources $subnet_ids 2>&1); then
        abort "$result"
    fi
    >&2 echo "Created tag KubernetesCluster=$tag on $subnet_ids"
}

configure_k8s() {
    role="$1"  # master or worker
    if [[ "$role" == "master" ]]; then
        snaps="kube-apiserver kube-controller-manager"
    else
        snaps="kubelet"
    fi
    for snap in $snaps; do
        echo "Configuring cloud-provider for $snap"
        result=$(juju run -m $JUJU_CONTROLLER:$JUJU_MODEL --format=yaml --application "kubernetes-$role" -- \
                 bash -c "snap set $snap cloud-provider=aws && service snap.$snap.daemon restart" 2>&1)
        if echo "$result" | grep -q 'ReturnCode: [^0]'; then
            abort "$result"
        fi
        >&2 echo "Configured cloud-provider=aws for $snap"
    done
}

enable_cni() {
    cluster_tag="$(juju model-config -m $JUJU_CONTROLLER:$JUJU_MODEL --format=tabular cdk-tag)"

    # loading policy & role docs, and creating profile
    load_iam_policy master
    load_iam_policy worker
    load_iam_role master
    load_iam_role worker
    create_instance_profile master
    create_instance_profile worker

    # connecting together all of the roles, policies, and profiles
    attach_policy_to_role master
    attach_policy_to_role worker
    add_role_to_profile master
    add_role_to_profile worker
    attach_profile_to_instances master
    attach_profile_to_instances worker

    # managing the tagging
    remove_shared_security_group_tag master
    remove_shared_security_group_tag worker
    # The model-config should ensure that all necessary resources are tagged
    # but during bootstrap it seems that tags sometimes don't get applied.
    # So here we're being explicit about ensuring everything that needs tagging
    # gets it so that we work out of the box.  Hopefully the model-config will
    # ensure the tag gets applied to any new units properly.
    tag_application master "$cluster_tag"
    tag_application worker "$cluster_tag"
    tag_subnets worker "$cluster_tag"

    # enable the config in the cluster
    configure_k8s master
    configure_k8s worker
}
